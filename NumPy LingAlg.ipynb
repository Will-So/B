{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduciton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The operations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first operations that I will be bringing to Blaze is `inner`, `SVD`, `Inverse`, and `Solve`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be consistent with `NumPy`, I will keep calling it the inner product instead of the dot product. The function should also work with multidimensional arrays and scalar values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(a,b), sum(a[:]*b[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some expressions will use `Matrix` as a base class and others will use `Vector`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How BLAS is structured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be a good idea to use the structure of `BLAS` when possible.It is split up into 3 levels\n",
    "\n",
    "1. Vector operations on strided arrays: dot products, vector norms. $y \\leftarrow \\alpha \\mathbf{x} + \\mathbf{y}$\n",
    "2. Matrix-vector operations including generalized matrix vector multiplication. $\\mathbf y \\leftarrow \\alpha A \\mathbf x + \\beta \\mathbf y$\n",
    "3. Matrix Matrix operation (GEMM) of the form $C \\leftarrow \\alpha A B + \\beta C$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminology\n",
    "\n",
    "| Name | Description\n",
    "-- | --\n",
    "Point | list of numbers called coordinates\n",
    "coordinate | specifiy point in space\n",
    "\n",
    "### Formulas\n",
    "\n",
    "Length is given by $\\sqrt{\\sum^n_{i=1}v_i^2}$. Vector addition and multiplication work as expected. The inner product is given by $\\vec{x} \\cdot \\vec{y} = \\sum^n_{i=1}x_iy_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\vec{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[This](http://www.ling.ohio-state.edu/~kbaker/pubs/Singular_Value_Decomposition_Tutorial.pdf) paper explains how SVD works very well. It also provides by far the best introduction to linear Algebra that I have ever seen. \n",
    "\n",
    "Kirk mentions the three interpretations of SVD\n",
    ">  1. Method for transforming correlated variables into a set of uncorrelated onces that better expose the various relationships among the original data items\n",
    " 2. Method for identifying and ordering the dimensions along which data points exhibit the most variation\n",
    " 3. Finding the best approximation of the original data points using fewer dimensions. i.e., a method for data reduction\n",
    "\n",
    "One of the first steps will be to require that.\n",
    "\n",
    "The general theorem is\n",
    "\n",
    "$$A_{mm} = U_{mm}S_{mm}V^T_{nn}$$\n",
    "\n",
    "Where $U^TU = I$, $V^TV = I$, Columns of  $U$ are orthonormal eigenvectors of $AA^T$. Columns of V are orthornmal eigenvectors of $A^TA$. $S$ is a diagonal matrix containing the square roots of eigenvalues from U or V in descending order. \n",
    "\n",
    "In order to find U, westart with $AA^T$. US is the interest thing. Document similarity by VS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
